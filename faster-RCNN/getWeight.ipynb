{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from roi_data_layer.roidb import combined_roidb, rank_roidb_ratio, filter_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "    adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FedUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.class_agnostic =False\n",
    "        self.epochs = 3\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay_step = 4\n",
    "        self.dataset = 'KAIST'\n",
    "        self.net = 'vgg16'\n",
    "        self.batch_size = 24\n",
    "        self.nw = 2\n",
    "        self.cuda = True\n",
    "        #self.round = 10\n",
    "        self.mGPUs=True\n",
    "        self.optimizer =\"sgd\"\n",
    "        self.k=5\n",
    "        #self.device = th.device(\"cpu\")\n",
    "        \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from data/pretrained_model/vgg16_caffe.pth\n",
      "Loading pretrained weights from data/pretrained_model/vgg16_caffe.pth\n",
      "Loading pretrained weights from data/pretrained_model/vgg16_caffe.pth\n"
     ]
    }
   ],
   "source": [
    "parties = 3\n",
    "round_i = 4\n",
    "#model_path = ['models/vgg16/KAIST/faster_rcnn_KAIST_3AVG/faster_rcnn_KAIST_campus_1_3_718.pth',\n",
    "#'models/vgg16/KAIST/faster_rcnn_KAIST_3AVG/faster_rcnn_KAIST_road_1_3_513.pth',\n",
    "#'models/vgg16/KAIST/faster_rcnn_KAIST_3AVG/faster_rcnn_KAIST_downtown_1_3_566.pth']\n",
    "model_path = ['models/vgg16/KAIST/wkAVG/faster_rcnn_KAIST_campus_'+str(round_i)+'_3_718.pth',\n",
    "'models/vgg16/KAIST/wkAVG/faster_rcnn_KAIST_road_'+str(round_i)+'_3_513.pth',\n",
    "'models/vgg16/KAIST/wkAVG/faster_rcnn_KAIST_downtown_'+str(round_i)+'_3_566.pth']\n",
    "\n",
    "\n",
    "imdb_classes =  ('__background__',  # always index 0\n",
    "                          'person',\n",
    "                          'people','cyclist'\n",
    "                         )\n",
    "\n",
    "model_list=[None] * parties\n",
    "for i in range(parties):\n",
    "    model_list[i],optimizer = FedUtils.load_model(imdb_classes,model_path[i], args,cfg)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_frcnn(img):\n",
    "    \"\"\" follow the processing steps of fasterRCNN\n",
    "    \"\"\"\n",
    "    img = np.asarray(img[:,:,::-1], dtype=np.float32)\n",
    "    PIXEL_MEANS = np.array([[[102.9801, 115.9465, 122.7717]]])\n",
    "    img -= PIXEL_MEANS\n",
    "    \n",
    "    \n",
    "    return torch.tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "BASE_DIR = '/home/superorange5/data/kaist_test/kaist_test_visible'\n",
    "file_names = [f for f in os.listdir(BASE_DIR) if '.png' in f]\n",
    "#scene_tags = [scene_tag(f) for f in file_names]\n",
    "\n",
    "imgs_raw = [imread(os.path.join(BASE_DIR, fn)) for fn in file_names]\n",
    "imgs = [preproc_frcnn(img).unsqueeze(0).permute(0, 3, 1, 2) for img in imgs_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg_pickle_path = 'testimg2252.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(testimg_pickle_path, 'wb') as handle:\n",
    "#     pickle.dump(imgs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testimg_pickle_path, 'rb') as handle:\n",
    "    test_images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frcnn_helper import *\n",
    "\n",
    "\n",
    "        \n",
    "def getWeight(test_images,model_list, args):\n",
    "    \n",
    "    wk_list = []\n",
    "    for fasterRCNN in model_list:\n",
    "        if args.mGPUs:\n",
    "            fasterRCNN = fasterRCNN.module\n",
    "        X = get_features(fasterRCNN, test_images, args.batch_size)/255.0\n",
    "        wk_value = within_cluster_dispersion(X, n_cluster=args.k)\n",
    "        wk_list.append(wk_value)\n",
    "        print(wk_value)\n",
    "    \n",
    "    return wk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(round_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0300931747670314\n",
      "4.143017952287369\n",
      "3.614508784792944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#i=1\n",
    "\n",
    "#wk_list_prev = [1.792,2.595,2.133]\n",
    "#wk_list_prev=[1.8834246677171604, 2.603966431543569, 1.8537786606301114]  #round1\n",
    "#wk_list_prev=[3.0300931747670314,4.143017952287369,3.614508784792944]  # round2\n",
    "wk_list_prev=[2.6206474483306246,3.016229260855767,2.688841387] #round3\n",
    "\n",
    "\n",
    "    \n",
    "with open(testimg_pickle_path, 'rb') as handle:\n",
    "    test_images = pickle.load(handle)\n",
    "# get within class dispersion        \n",
    "\n",
    "wk_list_curr = getWeight(test_images,model_list, args)\n",
    "if round_i==1:\n",
    "    wk_diff = wk_list_curr\n",
    "else:\n",
    "    wk_diff=[]\n",
    "    for list1_c, list2_p in zip(wk_list_prev, wk_list_curr):        \n",
    "        wk_diff.append(list1_c-list2_p)\n",
    "\n",
    "print('diff={}'.format(wk_diff))\n",
    "\n",
    "wk_ratio = softmax(wk_diff).tolist()    \n",
    "print('wk_ratio={}'.format(wk_ratio))\n",
    "wk_list_prev = wk_list_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff=[-0.40944572643640686, -1.1267886914316025, -0.9256673977929437]\n"
     ]
    }
   ],
   "source": [
    "wk_list1=[1.8834246677171604, 2.603966431543569, 1.8537786606301114]  #round1\n",
    "wk_list2=[3.0300931747670314,4.143017952287369,3.614508784792944]  # round2\n",
    "wk_list3=[2.6206474483306246,3.016229260855767,2.688841387] #round3\n",
    "\n",
    "wk_diff=[]\n",
    "for list1_c, list2_p in zip(wk_list3, wk_list2):        \n",
    "    wk_diff.append(list1_c-list2_p)\n",
    "print('diff={}'.format(wk_diff))\n",
    "from scipy.special import softmax\n",
    "I_ratio = softmax(wk_diff).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg by weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wk_ratio = [0.273744286,0.378889121,0.347366593] #wk_value_ratio round=2\n",
    "#wk_ratio = [0.273369509,0.384206358,0.342424133] #wk_value_ratio round=3\n",
    "#wk_ratio = [0.285985,0.394200378,0.319814622] #wk_value_ratio round=4\n",
    "\n",
    "#wk_ratio = [0.295141897,0.315678326,0.389179776]  #wk_diff_ratio round=1\n",
    "\n",
    "#wk_ratio = [0.239251713,0.48078381,0.279964477]  #wk_diff_ratio round=2\n",
    "#wk_ratio = [0.275741057,0.350559489,0.373699454] #wk_diff_ratio round=3\n",
    "wk_ratio = [0.229953847,0.349812376,0.420233777] #wk_diff_ratio round=4\n",
    "\n",
    "\n",
    "#wk_ratio = [0.16262228, 0.48690203, 0.35047569]  #softmax(wk_value) round=2\n",
    "#wk_ratio = [0.18246407,0.48292864,0.33460729]  #softmax(wk_value) round=3\n",
    "#wk_ratio =[0.23003816, 0.48038125, 0.28958059]#softmax(wk_value) round=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parties=2\n",
    "wk_ratio =  [1] * parties \n",
    "wk_ratio = [x / parties for x in wk_ratio]\n",
    "wk_ratio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=2\n",
    "output_dir='models/vgg16/KAIST/wkAVG'\n",
    "model_list = avgWeight(model_list,wk_ratio)\n",
    "\n",
    "\n",
    "\n",
    "save_name = os.path.join(output_dir, 'faster_rcnn_KAIST_AVG_{}_n.pth'.format(round_i))\n",
    "save_checkpoint({\n",
    "  #'session': 1,\n",
    "  'round': round_i,\n",
    "  'model':  model_list[0].module.state_dict() if args.mGPUs else model_list[0].state_dict(), \n",
    "  'optimizer': optimizer.state_dict(),\n",
    "  'pooling_mode': cfg.POOLING_MODE,\n",
    "  'class_agnostic': args.class_agnostic,\n",
    "}, save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23003816, 0.48038125, 0.28958059])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkvalue = [1.945940866,2.682275729,2.176129312]\n",
    "\n",
    "from scipy.special import softmax\n",
    "softmax(wkvalue)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterRCNN",
   "language": "python",
   "name": "fasterrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
